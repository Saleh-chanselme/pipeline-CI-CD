{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Pipeline CI/CD This project is a ML pipeline CI CD using the Iris dataset . It includes: A LogisticRegression model trained using scikit-learn . Model saved and tracked using MLflow . A FastAPI backend to serve predictions. minimal Streamlit frontend for testing. Use the menu on the left to explore the API and model documentation.","title":"Home"},{"location":"#pipeline-cicd","text":"This project is a ML pipeline CI CD using the Iris dataset . It includes: A LogisticRegression model trained using scikit-learn . Model saved and tracked using MLflow . A FastAPI backend to serve predictions. minimal Streamlit frontend for testing. Use the menu on the left to explore the API and model documentation.","title":"Pipeline CI/CD"},{"location":"api/","text":"API Documentation \u2014 Iris LogisticRegression Model 1. Overview This API is built with FastAPI and serves predictions from a LogisticRegression model trained on the Iris dataset. The model is tracked and loaded dynamically from MLflow . It provides two endpoints: GET / \u2192 Health check POST /predict \u2192 Predict the class of Iris flowers based on input features All API events are logged into app.log . 2. GET / Endpoint to check that the API is running. Request Response Example { \"status\": \"Ok\" } 3. POST /predict: Endpoint to send input features to the LogisticRegression model and receive predictions. Request Body { \"features\": [5.1, 3.5, 1.4, 0.2] } Response Example: { \"predictions\": [0] } Loading the Model: The model is loaded dynamically from MLflow using the latest run of a given experiment: import mlflow import mlflow.pyfunc def load_mlflow_model(experiment_id: str): client = mlflow.MlflowClient() runs = client.search_runs( experiment_ids=[experiment_id], order_by=[\"start_time DESC\"], max_results=1 ) latest_run = runs[0] run_id = latest_run.info.run_id model_uri = f\"runs:/{run_id}/model\" model = mlflow.pyfunc.load_model(model_uri) return model The API uses experiment_id=\"399503080388943605\". If the model fails to load, the /predict endpoint will return an error. run API fastapi dev app/ml_api.py","title":"API Documentation"},{"location":"api/#api-documentation-iris-logisticregression-model","text":"","title":"API Documentation \u2014 Iris LogisticRegression Model"},{"location":"api/#1-overview","text":"This API is built with FastAPI and serves predictions from a LogisticRegression model trained on the Iris dataset. The model is tracked and loaded dynamically from MLflow . It provides two endpoints: GET / \u2192 Health check POST /predict \u2192 Predict the class of Iris flowers based on input features All API events are logged into app.log .","title":"1. Overview"},{"location":"api/#2-get","text":"Endpoint to check that the API is running.","title":"2. GET /"},{"location":"api/#request","text":"","title":"Request"},{"location":"api/#response-example","text":"{ \"status\": \"Ok\" }","title":"Response Example"},{"location":"api/#3-post-predict","text":"Endpoint to send input features to the LogisticRegression model and receive predictions.","title":"3. POST /predict:"},{"location":"api/#request-body","text":"{ \"features\": [5.1, 3.5, 1.4, 0.2] }","title":"Request Body"},{"location":"api/#response-example_1","text":"{ \"predictions\": [0] }","title":"Response Example:"},{"location":"api/#loading-the-model","text":"The model is loaded dynamically from MLflow using the latest run of a given experiment: import mlflow import mlflow.pyfunc def load_mlflow_model(experiment_id: str): client = mlflow.MlflowClient() runs = client.search_runs( experiment_ids=[experiment_id], order_by=[\"start_time DESC\"], max_results=1 ) latest_run = runs[0] run_id = latest_run.info.run_id model_uri = f\"runs:/{run_id}/model\" model = mlflow.pyfunc.load_model(model_uri) return model The API uses experiment_id=\"399503080388943605\". If the model fails to load, the /predict endpoint will return an error.","title":"Loading the Model:"},{"location":"api/#run-api","text":"fastapi dev app/ml_api.py","title":"run API"},{"location":"frontend/","text":"Pipeline CI/CD ML Model Prediction App - Frontend Overview This frontend is built using Streamlit . It allows users to input features for the Iris dataset and get predictions from the ML model via a FastAPI backend. Features Input sliders for the following features: Sepal Length Sepal Width Petal Length Petal Width A Predict button to send data to the backend API. Display predicted class returned by the ML model. Error handling and logging for invalid inputs or API issues. Code Example import requests import streamlit as st import logging logger = logging.basicConfig(level=logging.INFO, filename=\"app.log\") logger = logging.getLogger(__name__) API_URL = \"http://127.0.0.1:8000/predict\" st.title(\"Welcome to our application\") st.header(\":red[ML Model Prediction App]\") sepal_length = st.slider(\"Sepal Length (e.g., 5.1)\", 0.0, 100.0, 0.1) sepal_width = st.slider(\"Sepal Width (e.g., 3.5)\", 0.0, 100.0, 0.1) petal_length = st.slider(\"Petal Length (e.g., 1.4)\", 0.0, 100.0, 0.1) petal_width = st.slider(\"Petal Width (e.g., 0.2)\", 0.0, 100.0, 0.1) if st.button(\"Predict\"): try: input_data = {\"features\": [sepal_length, sepal_width, petal_length, petal_width]} response = requests.post(url=API_URL, json=input_data) response.raise_for_status() if response.status_code == 200: predictions = response.json().get(\"predictions\") st.success(f\"Predicted class: {predictions}\") else: st.error(f\"API Error: {response.text}\") except ValueError: st.error(\"Please enter valid numeric values for all features.\") except requests.exceptions.RequestException as e: st.error(f\"Cannot reach API: {e}\") run APP Example : streamlit run app.py","title":"Frontend"},{"location":"frontend/#pipeline-cicd","text":"","title":"Pipeline CI/CD"},{"location":"frontend/#ml-model-prediction-app-frontend","text":"","title":"ML Model Prediction App - Frontend"},{"location":"frontend/#overview","text":"This frontend is built using Streamlit . It allows users to input features for the Iris dataset and get predictions from the ML model via a FastAPI backend.","title":"Overview"},{"location":"frontend/#features","text":"Input sliders for the following features: Sepal Length Sepal Width Petal Length Petal Width A Predict button to send data to the backend API. Display predicted class returned by the ML model. Error handling and logging for invalid inputs or API issues.","title":"Features"},{"location":"frontend/#code-example","text":"import requests import streamlit as st import logging logger = logging.basicConfig(level=logging.INFO, filename=\"app.log\") logger = logging.getLogger(__name__) API_URL = \"http://127.0.0.1:8000/predict\" st.title(\"Welcome to our application\") st.header(\":red[ML Model Prediction App]\") sepal_length = st.slider(\"Sepal Length (e.g., 5.1)\", 0.0, 100.0, 0.1) sepal_width = st.slider(\"Sepal Width (e.g., 3.5)\", 0.0, 100.0, 0.1) petal_length = st.slider(\"Petal Length (e.g., 1.4)\", 0.0, 100.0, 0.1) petal_width = st.slider(\"Petal Width (e.g., 0.2)\", 0.0, 100.0, 0.1) if st.button(\"Predict\"): try: input_data = {\"features\": [sepal_length, sepal_width, petal_length, petal_width]} response = requests.post(url=API_URL, json=input_data) response.raise_for_status() if response.status_code == 200: predictions = response.json().get(\"predictions\") st.success(f\"Predicted class: {predictions}\") else: st.error(f\"API Error: {response.text}\") except ValueError: st.error(\"Please enter valid numeric values for all features.\") except requests.exceptions.RequestException as e: st.error(f\"Cannot reach API: {e}\")","title":"Code Example"},{"location":"frontend/#run-app-example","text":"streamlit run app.py","title":"run APP Example :"},{"location":"model/","text":"LogisticRegression Model Documentation (Iris Dataset with MLflow) 1. Model Description This project uses a LogisticRegression model from scikit-learn to classify Iris flowers into three species: setosa versicolor virginica The model is trained, logged, and tracked using MLflow , including metrics and hyperparameters. 2. Dataset Dataset : Iris dataset (from scikit-learn) Features : sepal length (cm) sepal width (cm) petal length (cm) petal width (cm) Target : species of the flower The data is split into training (80%) and test (20%) sets using train_test_split . 3. Training and MLflow Tracking Hyperparameters params = { \"solver\": \"lbfgs\", \"max_iter\": 1000, \"multi_class\": \"auto\", \"random_state\": 8888, } Training Code Example: from sklearn.linear_model import LogisticRegression from sklearn.model_selection import train_test_split from sklearn import datasets import mlflow import mlflow.sklearn Load dataset X, y = datasets.load_iris(return_X_y=True) X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) Enable MLflow autologging mlflow.sklearn.autolog() Train LogisticRegression model lr = LogisticRegression(**params) lr.fit(X_train, y_train) Start MLflow run with mlflow.start_run(): mlflow.log_params(params) mlflow.sklearn.log_model(sk_model=lr, name=\"iris_model\") Example of logging metrics: from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score y_pred = lr.predict(X_test) mlflow.log_metric(\"accuracy\", accuracy_score(y_test, y_pred)) mlflow.log_metric(\"precision\", precision_score(y_test, y_pred, average=\"weighted\")) mlflow.log_metric(\"recall\", recall_score(y_test, y_pred, average=\"weighted\")) mlflow.log_metric(\"f1_score\", f1_score(y_test, y_pred, average=\"weighted\")) Save Model Locally: from pathlib import Path MODEL_DIR = Path(\"model\") MODEL_DIR.mkdir(exist_ok=True) mlflow.sklearn.save_model(lr, MODEL_DIR) Load Model for Predictions: import mlflow.pyfunc model_url = MODEL_DIR loaded_model = mlflow.pyfunc.load_model(model_url) predictions = loaded_model.predict(X_test)","title":"Model Documentation"},{"location":"model/#logisticregression-model-documentation-iris-dataset-with-mlflow","text":"","title":"LogisticRegression Model Documentation (Iris Dataset with MLflow)"},{"location":"model/#1-model-description","text":"This project uses a LogisticRegression model from scikit-learn to classify Iris flowers into three species: setosa versicolor virginica The model is trained, logged, and tracked using MLflow , including metrics and hyperparameters.","title":"1. Model Description"},{"location":"model/#2-dataset","text":"Dataset : Iris dataset (from scikit-learn) Features : sepal length (cm) sepal width (cm) petal length (cm) petal width (cm) Target : species of the flower The data is split into training (80%) and test (20%) sets using train_test_split .","title":"2. Dataset"},{"location":"model/#3-training-and-mlflow-tracking","text":"","title":"3. Training and MLflow Tracking"},{"location":"model/#hyperparameters","text":"params = { \"solver\": \"lbfgs\", \"max_iter\": 1000, \"multi_class\": \"auto\", \"random_state\": 8888, }","title":"Hyperparameters"},{"location":"model/#training-code-example","text":"from sklearn.linear_model import LogisticRegression from sklearn.model_selection import train_test_split from sklearn import datasets import mlflow import mlflow.sklearn","title":"Training Code Example:"},{"location":"model/#load-dataset","text":"X, y = datasets.load_iris(return_X_y=True) X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","title":"Load dataset"},{"location":"model/#enable-mlflow-autologging","text":"mlflow.sklearn.autolog()","title":"Enable MLflow autologging"},{"location":"model/#train-logisticregression-model","text":"lr = LogisticRegression(**params) lr.fit(X_train, y_train)","title":"Train LogisticRegression model"},{"location":"model/#start-mlflow-run","text":"with mlflow.start_run(): mlflow.log_params(params) mlflow.sklearn.log_model(sk_model=lr, name=\"iris_model\")","title":"Start MLflow run"},{"location":"model/#example-of-logging-metrics","text":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score y_pred = lr.predict(X_test) mlflow.log_metric(\"accuracy\", accuracy_score(y_test, y_pred)) mlflow.log_metric(\"precision\", precision_score(y_test, y_pred, average=\"weighted\")) mlflow.log_metric(\"recall\", recall_score(y_test, y_pred, average=\"weighted\")) mlflow.log_metric(\"f1_score\", f1_score(y_test, y_pred, average=\"weighted\"))","title":"Example of logging metrics:"},{"location":"model/#save-model-locally","text":"from pathlib import Path MODEL_DIR = Path(\"model\") MODEL_DIR.mkdir(exist_ok=True) mlflow.sklearn.save_model(lr, MODEL_DIR)","title":"Save Model Locally:"},{"location":"model/#load-model-for-predictions","text":"import mlflow.pyfunc model_url = MODEL_DIR loaded_model = mlflow.pyfunc.load_model(model_url) predictions = loaded_model.predict(X_test)","title":"Load Model for Predictions:"}]}